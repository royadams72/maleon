{"remainingRequest":"/Users/royadams/Google Drive/_WORK/ma-leon/angular_app/node_modules/@angular-devkit/build-optimizer/src/build-optimizer/webpack-loader.js??ref--3-1!/Users/royadams/Google Drive/_WORK/ma-leon/angular_app/node_modules/linkifyjs/lib/linkify.js","dependencies":[{"path":"/Users/royadams/Google Drive/_WORK/ma-leon/angular_app/node_modules/linkifyjs/lib/linkify.js","mtime":1520104782000},{"path":"/Users/royadams/Google Drive/_WORK/ma-leon/angular_app/node_modules/cache-loader/dist/cjs.js","mtime":1526906783979},{"path":"/Users/royadams/Google Drive/_WORK/ma-leon/angular_app/node_modules/@angular-devkit/build-optimizer/src/build-optimizer/webpack-loader.js","mtime":1519266497000}],"contextDependencies":[],"result":["'use strict';\n\nexports.__esModule = true;\nexports.tokenize = exports.test = exports.scanner = exports.parser = exports.options = exports.inherits = exports.find = undefined;\n\nvar _class = require('./linkify/utils/class');\n\nvar _options = require('./linkify/utils/options');\n\nvar options = _interopRequireWildcard(_options);\n\nvar _scanner = require('./linkify/core/scanner');\n\nvar scanner = _interopRequireWildcard(_scanner);\n\nvar _parser = require('./linkify/core/parser');\n\nvar parser = _interopRequireWildcard(_parser);\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nif (!Array.isArray) {\n\tArray.isArray = function (arg) {\n\t\treturn Object.prototype.toString.call(arg) === '[object Array]';\n\t};\n}\n\n/**\n\tConverts a string into tokens that represent linkable and non-linkable bits\n\t@method tokenize\n\t@param {String} str\n\t@return {Array} tokens\n*/\nvar tokenize = function tokenize(str) {\n\treturn parser.run(scanner.run(str));\n};\n\n/**\n\tReturns a list of linkable items in the given string.\n*/\nvar find = function find(str) {\n\tvar type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n\n\tvar tokens = tokenize(str);\n\tvar filtered = [];\n\n\tfor (var i = 0; i < tokens.length; i++) {\n\t\tvar token = tokens[i];\n\t\tif (token.isLink && (!type || token.type === type)) {\n\t\t\tfiltered.push(token.toObject());\n\t\t}\n\t}\n\n\treturn filtered;\n};\n\n/**\n\tIs the given string valid linkable text of some sort\n\tNote that this does not trim the text for you.\n\n\tOptionally pass in a second `type` param, which is the type of link to test\n\tfor.\n\n\tFor example,\n\n\t\ttest(str, 'email');\n\n\tWill return `true` if str is a valid email.\n*/\nvar test = function test(str) {\n\tvar type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n\n\tvar tokens = tokenize(str);\n\treturn tokens.length === 1 && tokens[0].isLink && (!type || tokens[0].type === type);\n};\n\n// Scanner and parser provide states and tokens for the lexicographic stage\n// (will be used to add additional link types)\nexports.find = find;\nexports.inherits = _class.inherits;\nexports.options = options;\nexports.parser = parser;\nexports.scanner = scanner;\nexports.test = test;\nexports.tokenize = tokenize;",null]}